{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools as itls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cytoolz as tlz\n",
    "from cytoolz import curried as tlzc\n",
    "\n",
    "c_starmap = tlz.curry(itls.starmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from text2math import raw2text as r2t\n",
    "from text2math import text2tokens as t2t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from h_topic_model import textproc_utils as tpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEGMENTED_SENTS_FILE = \"/Users/steven_c/projects/h_topic_model/data/labled_data/ex_segments/ex_sentences_w_segmented_words.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ANNOTATIONS_FILE = \"/Users/steven_c/projects/h_topic_model/data/labled_data/traindata.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_file_lines(filename):\n",
    "    with open(filename) as f:\n",
    "        return [r2t.adv_decode(txt) for txt in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89365"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LINES = load_file_lines(SEGMENTED_SENTS_FILE)\n",
    "len(LINES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing out the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SPLITMARKER = u\"f60968a6d89e\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OGMARKER = u\"~\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_txt(txt):\n",
    "    \"\"\"\n",
    "    Removes most of the punctuation.\n",
    "    \n",
    "    Applies text2math.text2tokens.drop_punct\n",
    "    then applies h_topic_model.textproc_utils.remove_h_punct.\n",
    "    \"\"\"\n",
    "    return tlz.pipe(txt,\n",
    "                    t2t.drop_punct,\n",
    "                    tpu.remove_h_punct(replace=u\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_seg_tokens(lines, ogmarker=OGMARKER, segmarker=SPLITMARKER):\n",
    "    return tlz.pipe(lines,\n",
    "                    tlzc.map(lambda token: token.replace(ogmarker, segmarker)),\n",
    "                    tlzc.map(tpu.basic_split),\n",
    "                    tlz.concat,\n",
    "                    tlzc.filter(lambda t: segmarker in t),  # Filter out tokens that are not segmented\n",
    "                    tlzc.map(clean_txt),\n",
    "                    tlzc.filter(tlz.identity),\n",
    "                    list,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.3 s, sys: 637 ms, total: 35.9 s\n",
      "Wall time: 37.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1178441"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time TOKENS = get_seg_tokens(LINES)\n",
    "len(TOKENS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding unique tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unique(seq):\n",
    "    return tlz.pipe(seq,\n",
    "                    set,\n",
    "                    list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 301 ms, sys: 2.45 ms, total: 304 ms\n",
      "Wall time: 310 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "104582"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time UTOKENS = unique(TOKENS)\n",
    "len(UTOKENS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting together compounds and annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_seg_marker(txt, replacement, segmarker=SPLITMARKER):\n",
    "    return txt.replace(segmarker, replacement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merg_segs(txt, segmarker=SPLITMARKER):\n",
    "    return replace_seg_marker(txt, u\"\", segmarker=segmarker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seg_marker_to_space(txt, segmarker=SPLITMARKER, replacement=u\" \"):\n",
    "    return replace_seg_marker(txt, replacement, segmarker=segmarker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_comps_and_annots(seq):\n",
    "    return tlz.pipe(seq,\n",
    "                    tlzc.groupby(merg_segs),\n",
    "                    lambda d: d.iteritems(),\n",
    "                    list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 294 ms, sys: 29.3 ms, total: 323 ms\n",
      "Wall time: 386 ms\n"
     ]
    }
   ],
   "source": [
    "%time GROUPED_ON_COMPS = make_comps_and_annots(UTOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_non_annots(seq):\n",
    "    return tlz.pipe(seq,\n",
    "                    c_starmap(lambda k, vs: (k, filter(lambda t: t != k, vs))),\n",
    "                    tlzc.filter(tlz.second), # filter out those that now have zero annotations.\n",
    "                    list)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 220 ms, sys: 10.1 ms, total: 230 ms\n",
      "Wall time: 229 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "104580"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time COMPOUNDS_AND_ANNOTATIONS = filter_non_annots(GROUPED_ON_COMPS)\n",
    "len(COMPOUNDS_AND_ANNOTATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 55.3 ms, sys: 17.4 ms, total: 72.7 ms\n",
      "Wall time: 61.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time MULTI = list(filter(lambda t: len(tlz.second(t)) > 1, COMPOUNDS_AND_ANNOTATIONS))\n",
    "len(MULTI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Annotation Strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Annotation file](http://morfessor.readthedocs.io/en/latest/filetypes.html#annotation-file)\n",
    "\n",
    "An annotation file contains one compound and one or more annotations per\n",
    "compound on each line. The separators between the annotations (default ', ')\n",
    "and between the constructions (default ' ') are configurable.\n",
    "\n",
    "**Specification**\n",
    "\n",
    "```\n",
    "<compound> <analysis1construction1>[ <analysis1constructionN>][, <analysis2construction1> [<analysis2constructionN>]*]*\n",
    "```\n",
    "\n",
    "**Example**\n",
    "```\n",
    "kahvikakku kahvi kakku, kahvi kak ku\n",
    "kahvikilon kahvi kilon\n",
    "kahvikoneemme kahvi konee mme, kah vi ko nee mme\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_comp_and_annot(seq):\n",
    "    return u\" \".join([seq[0], \", \".join(seq[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def comp_and_annot_string(seq):\n",
    "    return tlz.pipe(seq,\n",
    "                    format_comp_and_annot,\n",
    "                    seg_marker_to_space,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def comp_and_annot_strings(seq):\n",
    "    return tlz.map(comp_and_annot_string, seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 212 ms, sys: 5.32 ms, total: 217 ms\n",
      "Wall time: 241 ms\n"
     ]
    }
   ],
   "source": [
    "%time ANC_STRINGS = list(comp_and_annot_strings(COMPOUNDS_AND_ANNOTATIONS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(ANNOTATIONS_FILE, \"w+\") as f:\n",
    "    for line in ANC_STRINGS:\n",
    "        f.write(\"{}\\n\".format(line.encode(\"utf-8\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
